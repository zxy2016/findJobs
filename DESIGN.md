# 技术设计文档

## 1. 概述

本文档旨在阐述 FindJobs AI 助手的技术架构与设计。该系统利用网络爬虫和大型语言模型（LLM）技术，旨在实现求职过程的自动化和智能化。

## 2. 系统架构

系统由五个主要组件构成：

- **后端 (FastAPI 服务)**: 作为系统的核心，负责暴露 RESTful API、处理业务逻辑，并协调其他所有组件的交互。
- **爬虫服务 (Playwright)**: 一个负责从外部网站抓取岗位数据的模块。其设计具有良好的扩展性，能够支持多个招聘网站。
- **数据库 (MySQL)**: 持久化层，用于存储岗位列表、用户信息和生成的个人画像。
- **LLM 服务 (外部)**: 外部的 AI 服务（如 Google Gemini），用于自然语言理解、数据提取和智能匹配。
- **前端 (Web UI)**: 面向用户的交互界面，用于上传信息和查看工作推荐。（将在后续阶段开发）。

### 组件交互流程

1.  一个定时任务或 API 调用触发**爬虫服务**。
2.  爬虫抓取岗位数据并将其存入 **MySQL 数据库**。
3.  用户通过**前端**上传简历。
4.  **前端**将数据发送到**后端 API**。
5.  **后端**将用户数据发送到 **LLM 服务**进行分析。
6.  **LLM 服务**返回结构化的用户画像，**后端**将其保存到**数据库**。
7.  **后端**从**数据库**中查询岗位，并再次使用 **LLM 服务**，将用户画像与岗位描述进行比较，以找出匹配项。
8.  最终的推荐结果被发送回**前端**进行展示。

## 3. 后端设计 (FastAPI)

- **配置管理**: 应用配置通过 `.env` 文件管理，并在 `app.core.config` 中使用 Pydantic 的 `BaseSettings` 类进行加载。
- **API 端点设计 (v1 版本规划)**:
    - `POST /api/v1/scrape/run/{site_name}`: 手动触发针对特定网站的爬虫任务。
    - `GET /api/v1/scrape/status/{job_id}`: 检查爬虫任务的状态。
    - `POST /api/v1/profile/upload`: 上传简历文件进行分析。
    - `POST /api/v1/profile/analyze`: 提交文本进行分析。
    - `GET /api/v1/jobs/`: 搜索和筛选岗位信息。
    - `GET /api/v1/recommendations/`: 获取用户的个性化岗位推荐。

## 4. 爬虫模块设计

- **技术选型**: Playwright，因为它能很好地处理使用大量 JavaScript 动态加载内容的现代网站。
- **架构**: 将采用模块化、插件式的架构。
    - 一个抽象基类 `BaseScraper` 将定义通用接口（例如 `run()`, `extract_jobs()`, `save_to_db()`）。
    - 每个目标网站都将有其具体的实现类（例如 `HaierScraper(BaseScraper)`）。
    - 一个工厂函数将根据 `site_name` 参数实例化正确的爬虫。
- **执行方式**: 爬虫将作为后台任务执行（使用 FastAPI 的 `BackgroundTasks`），以避免阻塞 API 响应。

## 5. 数据库模式

我们将使用 SQLAlchemy 作为 ORM。初始的数据库表结构将包括：

- **`jobs` (岗位表)**
    - `id` (主键, 整型)
    - `title` (职位名称, 字符串)
    - `company` (公司, 字符串)
    - `location` (地点, 字符串)
    - `description` (职位描述, 文本)
    - `url` (原始链接, 字符串, 唯一)
    - `source_site` (来源网站, 字符串) # 例如: 'haier'
    - `scraped_at` (爬取时间, 日期时间)

- **`users` (用户表)**
    - `id` (主键, 整型)
    - `email` (邮箱, 字符串, 唯一, 可选)
    - `created_at` (创建时间, 日期时间)

- **`user_profiles` (用户画像表)**
    - `id` (主键, 整型)
    - `user_id` (外键, 关联 `users.id`)
    - `raw_content` (原始信息, 文本) # 原始的简历或对话文本
    - `structured_profile` (结构化画像, JSON) # 由 LLM 提取的结构化数据
    - `created_at` (创建时间, 日期时间)
    - `updated_at` (更新时间, 日期时间)

## 6. LLM 集成

- **接口**: 将定义一个通用的 `LLMClient` 来抽象与不同 LLM 服务商的交互。
- **灵活性**: 具体的实现（例如 `GeminiClient`, `OpenAIClient`）将根据 `.env` 文件中的 `LLM_PROVIDER` 设置在运行时被选择。
- **核心任务 & 提示词工程**:
    1.  **画像提取**: 设计详细的提示词，指示 LLM 从简历中提取关键信息（如技能、经验、教育背景），并以结构化的 JSON 对象返回。
    2.  **岗位匹配**: 设计第二个提示词，向 LLM 提供用户的结构化画像和一份岗位描述，要求它对匹配度进行评分并给出理由。