# 项目开发计划 (Project Development Plan)

本文档用于跟踪“FindJobs AI 助手”项目的开发进度。所有开发活动都将遵循此计划，并在每个步骤完成后更新此文档。

---

## 第一阶段：数据基础与爬虫框架

**目标:** 构建一个稳定、可扩展的爬虫服务以及用于存储岗位数据的数据库基础。

**阶段完成状态: [ 已完成 ]**

### 1.1 项目初始化
- [x] 创建 `requirements.txt` 文件，并写入初始依赖。
- [x] 创建 `.env.example` 文件，作为环境变量配置的模板。
- [x] 创建项目核心目录结构 (`app`, `scraper`, `core` 等)。
- [x] 创建 `README.md` (中文版)。
- [x] 创建 `DESIGN.md` (中文版)。
- [x] 创建 `DEVELOPMENT_PLAN.md` (本文件)。

### 1.2 数据库设置
- [x] **1.2.1**: 在 `app/models/` 中定义 `Job` 数据库模型 (`job.py`)。
- [x] **1.2.2**: 在 `app/db/` 中设置数据库引擎和会话管理 (`session.py`)。
- [x] **1.2.3**: 编写一个初始化脚本或在 `main.py` 中添加启动事件，用于在应用首次启动时创建数据库表。

### 1.3 爬虫核心设计
- [x] **1.3.1**: 在 `app/scraper/` 中设计并实现一个抽象基类 `BaseScraper` (`base.py`)，定义通用方法。
- [x] **1.3.2**: 在 FastAPI 中添加一个简单的 API 端点 (`/api/v1/scrape/{site_name}`) 来触发爬虫。

### 1.4 海尔招聘爬虫实现
- [x] **1.4.1**: 创建 `HaierScraper` 类 (`app/scraper/haier.py`)，继承自 `BaseScraper`。
- [x] **1.4.2**: 使用 Playwright 实现定位职位列表、自动翻页、提取单个职位详情（标题、描述、地点等）的逻辑。
- [x] **1.4.3**: 实现将提取到的数据通过数据库会话写入到 `jobs` 表的逻辑。
- [x] **1.4.4 (新增)**: 实现详情页详细信息（职责、要求等）的抓取。
- [x] **1.4.5 (新增)**: 实现高效的增量爬取逻辑，避免全量重复抓取。

### 1.5 测试 (第一阶段)
- [x] **1.5.1**: (单元测试) 编写测试用例验证 `Job` 模型的字段和类型是否正确。
- [x] **1.5.2**: (集成测试) 编写一个测试脚本，手动运行 `HaierScraper`，并断言数据库中成功插入了数据。

---

## 第二阶段：个人分析与AI集成

**目标:** 实现用户提交个人信息（简历、文本）的功能，并调用 LLM 服务完成个人画像的结构化分析。

**阶段完成状态: [ 未开始 ]**

- [ ] **2.1 LLM 客户端设计**: 设计 `LLMClient` 抽象基类，并实现一个具体的 `GeminiClient`。
- [ ] **2.2 数据库模型**: 创建 `User` 和 `UserProfile` 的数据库模型。
- [ ] **2.3 API 端点开发**: 创建用于文件上传 (`/profile/upload`) 和文本提交 (`/profile/analyze`) 的 API 端点。
- [ ] **2.4 核心逻辑实现**: 实现文件读取、构建 Prompt 并调用 LLM 服务、将返回的 JSON 画像存入数据库的完整流程。
- [ ] **2.5 测试 (第二阶段)**: 编写集成测试，调用分析 API 并验证 `user_profiles` 表中是否成功生成了画像数据。

---

## 第三阶段：智能匹配与推荐

**目标:** 基于用户画像和岗位数据，实现智能匹配，并通过 API 提供推荐结果。

**阶段完成状态: [ 未开始 ]**

- [ ] **3.1 API 端点开发**: 创建获取推荐结果的 API 端点 (`/recommendations`)。
- [ ] **3.2 核心匹配逻辑**: 实现从数据库检索画像和岗位、构建匹配 Prompt、调用 LLM 获取匹配度和理由、对结果进行排序和格式化的完整流程。
- [ ] **3.3 测试 (第三阶段)**: 编写端到端测试，模拟完整流程（上传->分析->推荐），并验证推荐结果的合理性。

---

## 第四阶段：优化与部署准备

**目标:** 优化系统，并将爬虫任务自动化，为最终部署做准备。

**阶段完成状态: [ 未开始 ]**

- [ ] **4.1 爬虫任务自动化**: 将手动触发的爬虫改造为由定时任务（如 Celery Beat 或 APScheduler）自动调度。
- [ ] **4.2 容器化**: 编写 `Dockerfile` 和 `docker-compose.yml`，实现应用的容器化部署。
- [ ] **4.3 文档完善**: 更新 `README.md` 中的部署说明，检查并完善所有代码注释和文档。
- [ ] **4.4 (可选) 前端开发**: 开发一个基础的前端页面，用于与后端 API 交互，提供完整的用户体验。